{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_img(img_tensor,num_imgs=1,size=(1,28,28)):\n",
    "    img_tensor=(img_tensor+1)/2\n",
    "    img_unflat = img_tensor.detach().cpu()\n",
    "    img_grid = make_grid(img_unflat[:num_imgs],nrow=5)\n",
    "    plt.imshow(img_grid.permute(1,2,0).squeeze())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10,im_chan=1,hidden_dim=64):\n",
    "        super(Generator,self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.conv_block(z_dim,hidden_dim*4),\n",
    "            self.conv_block(hidden_dim*4,hidden_dim*2,kernel_size=4,stride=1),\n",
    "            self.conv_block(hidden_dim*2,hidden_dim),\n",
    "            self.conv_block(hidden_dim,im_chan,kernel_size=4,final_layer=True)\n",
    "        )\n",
    "\n",
    "    def conv_block(self,input_ch,output_ch,kernel_size=3,stride=2,final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=input_ch,out_channels=output_ch,kernel_size=kernel_size,stride=stride),\n",
    "                nn.BatchNorm2d(num_features=output_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=input_ch,out_channels=output_ch,kernel_size=kernel_size,stride=stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        \n",
    "    def unsqueeze_noise(self,noise):\n",
    "        return noise.view(len(noise),self.z_dim,1,1)\n",
    "    \n",
    "    def forward(self,noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,im_ch=1,hidden_dim=16):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.conv_block(im_ch,hidden_dim),\n",
    "            self.conv_block(hidden_dim,hidden_dim*2),\n",
    "            self.conv_block(hidden_dim*2,1,final_layer=True)\n",
    "        )\n",
    "        \n",
    "    def conv_block(self,in_ch,out_ch,kernel_size=4,stride=2,final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=kernel_size,stride=stride),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=kernel_size,stride=stride)\n",
    "            )\n",
    "    def forward(self,image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred),-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_sample,z_dim,device='cpu'):\n",
    "    return torch.randn(n_sample,z_dim,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (gen): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(10, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "<generator object Module.named_parameters at 0x7f28ec034ba0>\n",
      "Discriminator(\n",
      "  (disc): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(32, 1, kernel_size=(4, 4), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "print(gen)\n",
    "print(gen.named_parameters())\n",
    "print(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: gen.0.0.weight, Shape: torch.Size([10, 256, 3, 3])\n",
      "Weights: tensor([[[[ 0.0019, -0.0084, -0.0146],\n",
      "          [-0.0018,  0.0061,  0.0031],\n",
      "          [-0.0205, -0.0133,  0.0107]],\n",
      "\n",
      "         [[ 0.0193, -0.0051,  0.0132],\n",
      "          [-0.0110, -0.0104, -0.0162],\n",
      "          [-0.0044, -0.0201, -0.0156]],\n",
      "\n",
      "         [[ 0.0186,  0.0076,  0.0034],\n",
      "          [-0.0162, -0.0026, -0.0016],\n",
      "          [-0.0029, -0.0071,  0.0158]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0167, -0.0093, -0.0027],\n",
      "          [ 0.0199,  0.0125, -0.0033],\n",
      "          [ 0.0037, -0.0018,  0.0009]],\n",
      "\n",
      "         [[ 0.0198,  0.0103, -0.0016],\n",
      "          [-0.0174, -0.0043,  0.0045],\n",
      "          [ 0.0194, -0.0064,  0.0033]],\n",
      "\n",
      "         [[-0.0003, -0.0056, -0.0114],\n",
      "          [-0.0157,  0.0078, -0.0106],\n",
      "          [ 0.0077,  0.0070,  0.0047]]],\n",
      "\n",
      "\n",
      "        [[[-0.0139,  0.0080,  0.0132],\n",
      "          [ 0.0055, -0.0120, -0.0206],\n",
      "          [ 0.0092,  0.0030, -0.0162]],\n",
      "\n",
      "         [[ 0.0011, -0.0138,  0.0129],\n",
      "          [-0.0110, -0.0139,  0.0179],\n",
      "          [-0.0108, -0.0089, -0.0188]],\n",
      "\n",
      "         [[ 0.0017,  0.0176,  0.0003],\n",
      "          [-0.0170, -0.0207,  0.0183],\n",
      "          [-0.0052, -0.0182,  0.0045]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0143,  0.0179, -0.0041],\n",
      "          [-0.0077,  0.0198, -0.0051],\n",
      "          [-0.0131,  0.0154, -0.0180]],\n",
      "\n",
      "         [[-0.0005,  0.0087,  0.0032],\n",
      "          [ 0.0009, -0.0057,  0.0078],\n",
      "          [ 0.0148, -0.0141, -0.0015]],\n",
      "\n",
      "         [[-0.0133, -0.0018,  0.0063],\n",
      "          [ 0.0098, -0.0034,  0.0060],\n",
      "          [ 0.0116, -0.0073,  0.0202]]],\n",
      "\n",
      "\n",
      "        [[[-0.0017,  0.0065, -0.0131],\n",
      "          [ 0.0137, -0.0201,  0.0033],\n",
      "          [-0.0172,  0.0036, -0.0185]],\n",
      "\n",
      "         [[ 0.0119, -0.0033,  0.0114],\n",
      "          [-0.0039,  0.0186,  0.0115],\n",
      "          [-0.0022,  0.0113,  0.0139]],\n",
      "\n",
      "         [[-0.0148,  0.0068, -0.0152],\n",
      "          [-0.0086,  0.0070,  0.0008],\n",
      "          [ 0.0203, -0.0194, -0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0146,  0.0157, -0.0172],\n",
      "          [ 0.0166, -0.0180, -0.0202],\n",
      "          [-0.0055,  0.0050, -0.0148]],\n",
      "\n",
      "         [[ 0.0112,  0.0013, -0.0003],\n",
      "          [ 0.0005,  0.0071, -0.0030],\n",
      "          [ 0.0153,  0.0071, -0.0059]],\n",
      "\n",
      "         [[-0.0014, -0.0197,  0.0079],\n",
      "          [ 0.0040,  0.0160,  0.0117],\n",
      "          [ 0.0082, -0.0022, -0.0094]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0107,  0.0106, -0.0014],\n",
      "          [ 0.0034, -0.0060, -0.0129],\n",
      "          [-0.0077,  0.0189, -0.0092]],\n",
      "\n",
      "         [[ 0.0151,  0.0093, -0.0086],\n",
      "          [ 0.0197,  0.0103, -0.0118],\n",
      "          [-0.0046,  0.0146,  0.0192]],\n",
      "\n",
      "         [[-0.0015,  0.0138,  0.0132],\n",
      "          [ 0.0083,  0.0110, -0.0070],\n",
      "          [-0.0019, -0.0129,  0.0179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0157, -0.0039, -0.0036],\n",
      "          [ 0.0042,  0.0080,  0.0032],\n",
      "          [-0.0042, -0.0036, -0.0130]],\n",
      "\n",
      "         [[ 0.0096,  0.0177,  0.0025],\n",
      "          [-0.0161, -0.0138,  0.0047],\n",
      "          [ 0.0195, -0.0113,  0.0111]],\n",
      "\n",
      "         [[ 0.0033, -0.0131, -0.0130],\n",
      "          [-0.0164, -0.0065, -0.0121],\n",
      "          [ 0.0080,  0.0076,  0.0045]]],\n",
      "\n",
      "\n",
      "        [[[-0.0061, -0.0118, -0.0113],\n",
      "          [-0.0171,  0.0077,  0.0146],\n",
      "          [ 0.0031, -0.0085, -0.0121]],\n",
      "\n",
      "         [[-0.0012,  0.0164, -0.0146],\n",
      "          [-0.0070,  0.0203,  0.0156],\n",
      "          [-0.0112, -0.0103, -0.0109]],\n",
      "\n",
      "         [[-0.0018,  0.0102, -0.0061],\n",
      "          [ 0.0198,  0.0090, -0.0182],\n",
      "          [-0.0036, -0.0110, -0.0147]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0201, -0.0169, -0.0130],\n",
      "          [ 0.0158, -0.0020, -0.0057],\n",
      "          [ 0.0164,  0.0089, -0.0078]],\n",
      "\n",
      "         [[ 0.0094, -0.0165,  0.0051],\n",
      "          [-0.0104,  0.0067,  0.0004],\n",
      "          [ 0.0136, -0.0059,  0.0195]],\n",
      "\n",
      "         [[ 0.0036,  0.0022,  0.0051],\n",
      "          [-0.0153, -0.0164, -0.0030],\n",
      "          [-0.0124, -0.0019, -0.0043]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0177,  0.0182, -0.0168],\n",
      "          [-0.0156,  0.0069,  0.0202],\n",
      "          [ 0.0090,  0.0124, -0.0028]],\n",
      "\n",
      "         [[-0.0147, -0.0025, -0.0159],\n",
      "          [ 0.0190,  0.0116,  0.0090],\n",
      "          [ 0.0133,  0.0134, -0.0155]],\n",
      "\n",
      "         [[-0.0091, -0.0113,  0.0014],\n",
      "          [ 0.0206, -0.0011, -0.0091],\n",
      "          [ 0.0014, -0.0040, -0.0194]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0196, -0.0034, -0.0149],\n",
      "          [-0.0183, -0.0042, -0.0020],\n",
      "          [-0.0132,  0.0162, -0.0082]],\n",
      "\n",
      "         [[ 0.0048,  0.0066, -0.0158],\n",
      "          [-0.0155, -0.0049, -0.0136],\n",
      "          [ 0.0186, -0.0078,  0.0137]],\n",
      "\n",
      "         [[ 0.0048,  0.0002, -0.0064],\n",
      "          [ 0.0127,  0.0057,  0.0189],\n",
      "          [ 0.0081, -0.0049, -0.0127]]]])\n",
      "------------------------\n",
      "Layer: gen.0.0.bias, Shape: torch.Size([256])\n",
      "Weights: tensor([ 1.4272e-02, -2.0347e-02, -5.7360e-03,  2.8740e-03, -1.9469e-02,\n",
      "        -1.9522e-02, -6.3594e-03, -1.7914e-02,  7.4246e-03,  5.4937e-04,\n",
      "        -6.3169e-03, -1.3860e-02, -6.5989e-03, -1.9584e-02, -2.0752e-02,\n",
      "        -1.2976e-02,  1.8833e-02,  1.0567e-02, -1.7212e-02,  1.0720e-02,\n",
      "        -1.4888e-02,  2.6553e-03, -2.8571e-03, -1.5233e-02,  1.7702e-02,\n",
      "        -1.9228e-02,  1.2556e-02, -8.7123e-03,  1.4908e-02,  1.2698e-02,\n",
      "        -1.0558e-02,  1.1906e-02, -1.3521e-02, -1.8130e-02, -4.2524e-03,\n",
      "        -7.9648e-03, -1.4806e-02,  1.4536e-02,  9.7674e-03, -1.2793e-02,\n",
      "        -2.5057e-03, -6.9109e-03,  1.1358e-02,  1.3533e-02, -2.0193e-02,\n",
      "         1.4367e-03, -3.4272e-03, -1.5437e-03,  2.0745e-02,  1.1384e-02,\n",
      "         1.2183e-02,  1.9226e-02,  4.6729e-03,  1.4297e-02, -8.7947e-03,\n",
      "         2.8700e-03, -1.5509e-02, -2.0040e-02,  7.4341e-03, -1.6928e-02,\n",
      "        -1.4273e-02, -7.8283e-03,  1.9063e-02, -2.0113e-02, -1.8079e-02,\n",
      "        -1.7648e-02, -6.9937e-03, -1.7875e-02, -2.6939e-03,  1.0714e-02,\n",
      "        -3.7391e-03,  1.3099e-02, -1.6259e-02, -8.5469e-03, -1.5594e-02,\n",
      "        -5.4897e-03,  8.6243e-03,  9.4250e-03, -1.0547e-02,  8.4759e-03,\n",
      "        -1.0485e-02,  1.8553e-02, -1.9282e-02,  1.7059e-02, -1.5476e-02,\n",
      "         1.5408e-02,  1.3415e-02,  1.7118e-02,  2.3313e-03, -2.0395e-02,\n",
      "        -1.2190e-02,  9.4046e-03, -1.0324e-02,  6.5081e-03, -5.1273e-03,\n",
      "         7.5303e-03, -1.5757e-02, -1.1974e-02,  8.2934e-03,  1.2618e-02,\n",
      "         1.5706e-02,  9.3401e-03,  1.4762e-02,  3.0538e-03,  8.5310e-03,\n",
      "         3.2326e-03,  1.9660e-02, -1.0993e-02,  1.6513e-02, -7.5324e-03,\n",
      "         4.9335e-03,  5.4622e-03,  1.3936e-02,  8.0823e-03,  6.0789e-03,\n",
      "         1.9286e-02,  8.2595e-03,  8.4829e-03,  1.8855e-02, -1.7723e-02,\n",
      "        -1.1849e-02, -8.4003e-03, -9.7203e-03, -4.7211e-03, -2.4094e-03,\n",
      "        -1.2233e-02, -3.5016e-03, -5.0934e-03,  9.6142e-03, -1.5662e-02,\n",
      "        -1.2851e-02,  2.1574e-03, -1.6429e-02,  2.0752e-02,  7.2479e-04,\n",
      "         1.5514e-02,  1.4619e-02,  1.2262e-02,  1.5290e-02, -1.0724e-02,\n",
      "        -1.9752e-02,  6.8128e-03,  1.5440e-02,  6.1105e-03,  8.9710e-05,\n",
      "        -1.3372e-02,  1.9413e-03, -8.2198e-03,  1.1493e-02, -5.3941e-04,\n",
      "        -6.8689e-03, -1.6431e-02,  1.0886e-02,  2.0461e-02, -1.1735e-02,\n",
      "         1.1837e-02,  6.7860e-03,  1.6837e-02,  1.1708e-03,  8.5948e-03,\n",
      "         2.0569e-02, -1.8396e-02,  1.9051e-02,  1.3266e-02, -1.5791e-03,\n",
      "        -2.0257e-02,  7.5063e-03, -2.9229e-03,  8.1793e-03,  1.1503e-02,\n",
      "        -1.7660e-02, -2.0141e-02,  2.0781e-03,  1.9160e-02, -2.8128e-03,\n",
      "        -1.4096e-02, -1.8796e-02,  3.3282e-03, -1.2823e-02, -1.9719e-02,\n",
      "        -2.9725e-03,  1.6192e-02, -1.6285e-02,  1.8925e-02, -1.7118e-02,\n",
      "         1.5801e-02, -1.5554e-02, -4.4361e-03,  1.9373e-02,  1.1573e-02,\n",
      "         1.2543e-02, -2.0219e-02, -1.7308e-02,  5.8379e-04,  1.4425e-02,\n",
      "        -2.0425e-03,  9.9033e-03, -5.3194e-03,  8.1251e-03, -1.3350e-02,\n",
      "         1.0580e-02,  1.7987e-02, -1.8362e-02,  1.4737e-02, -9.5595e-03,\n",
      "         6.8471e-03, -1.8730e-02,  3.8794e-03, -1.9943e-02,  1.3773e-02,\n",
      "         2.0166e-02, -1.5647e-03, -3.4256e-03,  6.1776e-03, -1.4073e-02,\n",
      "        -3.0037e-03, -1.5404e-02,  1.8183e-02, -1.0519e-02,  7.6477e-03,\n",
      "         1.8018e-02,  1.1016e-02, -4.8387e-05, -5.0490e-03, -1.0518e-02,\n",
      "        -1.8837e-02, -1.8223e-02, -6.2114e-03, -1.1861e-02, -9.5639e-03,\n",
      "         1.7550e-02, -1.9962e-02,  1.3471e-03,  1.8735e-02, -4.8584e-03,\n",
      "         2.0368e-02, -1.4170e-02, -1.2088e-02,  8.4274e-03,  3.1771e-04,\n",
      "         1.6448e-02,  6.0811e-03, -1.2699e-02, -7.2063e-03,  1.7803e-02,\n",
      "         2.0333e-02,  1.9514e-02,  8.2288e-04,  8.3149e-03,  2.1145e-03,\n",
      "        -1.8748e-02, -7.5428e-03,  5.6477e-03,  5.4097e-03,  2.0029e-02,\n",
      "         1.3599e-02])\n",
      "------------------------\n",
      "Layer: gen.0.1.weight, Shape: torch.Size([256])\n",
      "Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "------------------------\n",
      "Layer: gen.0.1.bias, Shape: torch.Size([256])\n",
      "Weights: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "------------------------\n",
      "Layer: gen.1.0.weight, Shape: torch.Size([256, 128, 4, 4])\n",
      "Weights: tensor([[[[ 3.8439e-04,  1.4186e-02, -9.2410e-03,  1.1587e-03],\n",
      "          [-1.5377e-03,  7.8764e-03, -7.1245e-03,  1.6205e-02],\n",
      "          [ 7.7579e-03, -9.4190e-03, -1.5509e-02, -1.3123e-02],\n",
      "          [ 1.2678e-02,  6.2818e-03,  1.4059e-02,  8.4229e-03]],\n",
      "\n",
      "         [[ 6.4709e-03, -6.8997e-03, -3.9524e-03, -8.2645e-03],\n",
      "          [-3.3383e-03,  5.4811e-03, -3.3978e-03,  1.0687e-03],\n",
      "          [-9.9955e-03,  1.4350e-02, -2.0304e-03,  7.8462e-03],\n",
      "          [-5.9530e-03,  2.0825e-02,  2.0476e-02, -7.2059e-03]],\n",
      "\n",
      "         [[ 1.8854e-02,  1.1144e-02, -1.4328e-02,  2.1529e-02],\n",
      "          [-7.9596e-04,  2.1052e-02, -7.8497e-03, -1.0915e-02],\n",
      "          [-1.1152e-03,  1.2145e-02, -1.3149e-02,  1.7390e-03],\n",
      "          [ 1.7889e-02, -4.8006e-03,  8.5495e-03, -7.1450e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3460e-03, -2.2089e-03,  1.1458e-02, -6.2971e-03],\n",
      "          [-6.1152e-03,  1.9735e-02, -2.0701e-02,  8.3044e-03],\n",
      "          [-1.0624e-02, -2.1334e-03, -7.4704e-03,  2.1283e-02],\n",
      "          [-6.3437e-03, -1.3286e-02,  6.3854e-03,  1.5604e-02]],\n",
      "\n",
      "         [[ 1.2094e-02,  1.0734e-02, -5.0789e-03, -2.1952e-02],\n",
      "          [ 1.9550e-02, -1.2373e-02,  3.3067e-05, -1.2040e-02],\n",
      "          [ 2.0733e-02,  6.7304e-03,  1.9269e-02,  1.2193e-02],\n",
      "          [-8.9767e-03,  1.2343e-02,  1.4416e-02,  9.8326e-03]],\n",
      "\n",
      "         [[ 1.5978e-02,  1.0981e-02, -2.0665e-02,  1.2538e-02],\n",
      "          [ 1.6048e-02, -1.9792e-03,  2.3793e-03, -1.3300e-02],\n",
      "          [ 1.5451e-02,  2.0271e-02,  2.0673e-02,  5.4969e-04],\n",
      "          [-7.2776e-03,  6.0548e-03, -1.0581e-02, -2.1160e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2748e-03,  1.2417e-03,  1.9567e-02, -6.1652e-03],\n",
      "          [-1.3183e-02, -8.0564e-03, -1.4450e-02,  5.7743e-03],\n",
      "          [-1.0549e-02,  1.4507e-03, -1.4731e-02,  1.6651e-02],\n",
      "          [-1.7478e-02,  2.1130e-02,  9.7252e-03,  2.0574e-02]],\n",
      "\n",
      "         [[-1.8905e-02, -4.3426e-03, -1.9005e-02, -6.0557e-03],\n",
      "          [ 1.1951e-02,  5.7701e-03, -2.4901e-03, -1.7693e-02],\n",
      "          [-4.2626e-03,  2.8717e-03, -6.0890e-03, -1.1889e-02],\n",
      "          [ 1.5564e-02, -1.1110e-02, -1.6159e-02,  6.9181e-03]],\n",
      "\n",
      "         [[ 1.3190e-02, -1.1123e-02,  2.8837e-03, -7.1914e-03],\n",
      "          [-6.3326e-03, -7.1694e-03,  1.0369e-02,  2.5615e-03],\n",
      "          [ 5.5683e-03,  1.0378e-02, -6.2229e-03, -1.2594e-02],\n",
      "          [ 1.3986e-02, -1.6089e-02,  1.3515e-02, -7.1652e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1896e-02, -9.9416e-03,  2.2992e-03, -5.7166e-03],\n",
      "          [-1.0875e-02, -2.0436e-02,  1.9000e-02, -8.7251e-03],\n",
      "          [-1.0091e-02, -1.0760e-03,  4.1586e-03,  1.2915e-04],\n",
      "          [-1.5461e-02, -5.2482e-03,  1.0656e-02,  1.7268e-02]],\n",
      "\n",
      "         [[-9.9343e-03,  1.5148e-02,  6.4246e-04, -1.6430e-02],\n",
      "          [-5.1918e-03,  1.1168e-02, -1.9633e-02,  1.1733e-02],\n",
      "          [-8.8107e-03,  4.8650e-03, -9.3600e-03, -1.2628e-03],\n",
      "          [ 1.3086e-02, -1.1763e-02, -9.3796e-03, -2.0390e-02]],\n",
      "\n",
      "         [[ 2.1105e-02, -1.3520e-02, -1.9924e-02, -8.6267e-03],\n",
      "          [ 1.2786e-02, -1.8326e-02,  1.7522e-02, -3.9384e-03],\n",
      "          [-1.2777e-02,  1.9403e-02,  1.6980e-03,  1.1638e-02],\n",
      "          [-8.3234e-03,  1.3432e-02,  1.9942e-02,  5.9399e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.8117e-06, -2.3830e-03,  4.4126e-03,  1.1887e-02],\n",
      "          [ 1.3230e-02, -8.8876e-04, -2.0274e-02,  2.2136e-03],\n",
      "          [-1.1822e-02,  1.8319e-02,  7.2941e-03, -1.3199e-02],\n",
      "          [ 4.7585e-03,  6.1628e-03, -2.3395e-03,  1.5031e-02]],\n",
      "\n",
      "         [[ 9.0239e-03,  6.6947e-03,  1.6412e-02,  1.0637e-02],\n",
      "          [ 1.6724e-02,  1.5347e-03, -6.1499e-03,  1.2739e-02],\n",
      "          [ 1.8970e-02, -1.0284e-02, -1.1114e-02,  1.4253e-02],\n",
      "          [ 2.4162e-03,  1.1722e-02,  1.8470e-02, -2.0369e-02]],\n",
      "\n",
      "         [[ 2.1614e-02, -2.0166e-02,  1.8691e-02, -6.7246e-03],\n",
      "          [ 9.7178e-04,  2.1055e-02, -2.7209e-03, -2.1287e-02],\n",
      "          [ 4.3459e-03,  2.0611e-02, -8.8997e-03, -1.8850e-02],\n",
      "          [-9.0840e-03, -3.4081e-03,  4.3996e-03,  1.3551e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5812e-03, -2.0746e-02, -1.3172e-03, -1.1280e-02],\n",
      "          [ 1.9686e-02,  1.8617e-03,  1.0759e-02,  1.0010e-02],\n",
      "          [ 1.2795e-02, -9.6834e-03,  1.0900e-02, -1.5309e-02],\n",
      "          [ 7.9595e-04, -2.1013e-02, -2.6768e-03, -1.4097e-02]],\n",
      "\n",
      "         [[ 2.0379e-02, -4.9798e-03, -1.0007e-02, -8.8734e-03],\n",
      "          [-7.4763e-03, -9.1310e-03,  1.5853e-02, -8.0368e-03],\n",
      "          [ 1.6380e-02,  1.9542e-02, -6.0443e-03, -1.8648e-02],\n",
      "          [-8.4265e-03, -1.7455e-02, -8.4146e-03,  1.3728e-02]],\n",
      "\n",
      "         [[-1.7310e-02, -9.8651e-03, -2.8195e-03,  1.4715e-02],\n",
      "          [ 1.8830e-03, -1.9366e-03,  2.4094e-03,  2.1236e-02],\n",
      "          [-1.5583e-02, -1.0209e-03, -1.9235e-02,  2.0625e-04],\n",
      "          [ 2.0984e-02, -5.4739e-03, -8.0964e-03, -5.6173e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.9986e-02, -8.1713e-03, -9.2105e-03, -2.3237e-03],\n",
      "          [ 2.2308e-03,  1.2486e-02, -4.6144e-03, -1.0937e-02],\n",
      "          [ 1.8659e-02,  2.1227e-02, -1.3522e-03, -2.1695e-02],\n",
      "          [-2.1257e-02,  9.0662e-03,  1.1553e-02,  2.0806e-02]],\n",
      "\n",
      "         [[-5.3138e-03, -1.3341e-02, -2.0428e-02, -1.0696e-02],\n",
      "          [-8.2154e-04, -1.2718e-02,  4.9727e-03, -1.1870e-02],\n",
      "          [ 2.8224e-03, -1.8217e-02, -1.1723e-02, -1.2219e-02],\n",
      "          [ 1.2422e-02,  5.9776e-03, -1.6457e-02, -1.1122e-04]],\n",
      "\n",
      "         [[ 1.5488e-02,  1.8975e-02, -4.0575e-03,  1.0461e-02],\n",
      "          [ 1.2713e-02, -1.8454e-02, -1.6375e-02, -9.6486e-03],\n",
      "          [-3.9257e-04, -3.5609e-03, -1.4163e-02, -3.7153e-03],\n",
      "          [ 2.0735e-02, -9.5967e-03, -1.2926e-02,  2.0780e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9629e-02, -1.4783e-02, -1.0189e-02,  1.8527e-02],\n",
      "          [-1.4992e-02, -1.9504e-02, -1.3947e-02,  2.0340e-02],\n",
      "          [-3.2981e-03, -2.0416e-02, -6.1213e-03, -6.7340e-03],\n",
      "          [ 4.4683e-03, -6.2239e-03, -2.9321e-03,  9.3006e-03]],\n",
      "\n",
      "         [[-1.8417e-03,  1.1459e-02,  3.7944e-03,  1.7042e-02],\n",
      "          [-1.4803e-02, -1.9986e-02,  1.8710e-02, -1.2877e-02],\n",
      "          [-7.2388e-03,  2.9071e-03, -1.6294e-02, -1.7716e-02],\n",
      "          [-1.7901e-02, -3.0654e-03, -8.9891e-04,  1.7318e-02]],\n",
      "\n",
      "         [[-1.7061e-02,  7.9859e-03, -1.1116e-02, -1.6783e-02],\n",
      "          [-3.3485e-03,  1.2448e-03, -2.1039e-02, -1.1682e-02],\n",
      "          [-2.0041e-02,  1.3742e-02, -1.7646e-02,  3.9765e-03],\n",
      "          [ 1.9831e-02, -1.6046e-02, -1.4403e-02,  1.2928e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4695e-02, -1.5054e-02,  1.9505e-02, -1.0313e-02],\n",
      "          [-7.7112e-03, -7.5561e-03,  1.6762e-02,  8.2442e-03],\n",
      "          [-1.3739e-02,  1.1572e-02, -4.2957e-03,  1.0340e-02],\n",
      "          [-2.4364e-03, -9.4985e-03,  1.8544e-02, -1.0805e-02]],\n",
      "\n",
      "         [[-6.0234e-03,  5.7488e-03, -1.6591e-02,  1.8848e-02],\n",
      "          [ 1.4908e-02,  6.0715e-03, -1.4260e-02,  1.4202e-02],\n",
      "          [-4.5242e-03, -4.5335e-03,  2.1326e-02, -7.4142e-04],\n",
      "          [-1.3772e-02,  8.0400e-03,  3.9166e-03,  9.7002e-03]],\n",
      "\n",
      "         [[ 6.0066e-03,  2.1373e-02,  1.5299e-03,  1.0688e-02],\n",
      "          [ 9.5835e-03,  1.5848e-02, -1.7064e-02, -6.8106e-03],\n",
      "          [-7.2223e-03,  1.9355e-02,  1.8369e-02,  9.8141e-03],\n",
      "          [ 1.8708e-02, -1.3509e-02, -2.1823e-02,  4.1415e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7538e-03,  8.3212e-03, -2.0906e-02, -1.8021e-02],\n",
      "          [-6.8628e-04,  6.8624e-03, -2.7530e-03, -1.6637e-02],\n",
      "          [-4.0936e-03, -5.5028e-03, -1.5860e-02,  1.3328e-02],\n",
      "          [-1.9635e-02, -2.5795e-03, -9.2165e-03, -2.0185e-02]],\n",
      "\n",
      "         [[ 1.0748e-02, -1.2054e-02, -6.0262e-03,  2.4034e-03],\n",
      "          [-2.9412e-03,  8.1218e-04,  3.7647e-03,  2.0539e-02],\n",
      "          [-6.4275e-03, -4.8452e-03,  7.2134e-03, -4.9248e-03],\n",
      "          [-3.6054e-03,  5.5731e-03, -1.5667e-02,  7.2143e-03]],\n",
      "\n",
      "         [[-1.8088e-02, -2.0013e-02,  7.2430e-03,  1.7807e-02],\n",
      "          [-1.8625e-02, -1.6920e-02,  1.5993e-02,  1.2310e-02],\n",
      "          [ 6.9887e-03,  2.2710e-03,  3.2632e-03, -1.8347e-03],\n",
      "          [-4.8520e-03, -1.6262e-02,  2.9704e-03,  1.3816e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5357e-02, -2.0228e-03,  1.5261e-02, -9.7038e-03],\n",
      "          [-1.6508e-02,  1.7662e-02,  1.7422e-02,  4.8239e-03],\n",
      "          [ 1.2972e-02, -2.0298e-02, -1.7243e-02, -9.1353e-03],\n",
      "          [-1.1898e-02,  1.7464e-02,  4.8736e-03, -2.0162e-02]],\n",
      "\n",
      "         [[-2.0731e-02, -1.3064e-02,  1.1780e-02, -6.1560e-03],\n",
      "          [ 1.7358e-02,  1.0889e-02,  1.1621e-02, -1.3220e-02],\n",
      "          [-1.6767e-02,  1.8877e-02, -1.7323e-02,  4.2718e-03],\n",
      "          [ 1.3513e-02, -5.1817e-03,  7.2241e-03, -1.9325e-02]],\n",
      "\n",
      "         [[ 1.2386e-02,  2.1904e-02,  1.4783e-02, -8.4156e-03],\n",
      "          [-1.3665e-02,  3.4464e-03, -9.6242e-03,  7.2689e-03],\n",
      "          [-6.0663e-03, -5.8992e-03,  1.8066e-02, -5.5213e-03],\n",
      "          [-6.5204e-03, -1.2021e-02,  4.1750e-03, -6.7641e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0958e-02,  1.5050e-02,  8.7831e-03,  1.3888e-02],\n",
      "          [ 2.0061e-02, -6.0237e-03,  2.8602e-03, -1.9230e-02],\n",
      "          [ 1.7237e-03, -1.9040e-02,  9.9163e-04, -5.2035e-03],\n",
      "          [-8.8852e-03, -2.9872e-03, -1.9939e-02, -2.1885e-02]],\n",
      "\n",
      "         [[-2.1349e-02, -1.8785e-02, -4.5194e-03,  5.4585e-03],\n",
      "          [ 3.2233e-03,  7.4034e-03,  1.7904e-02,  1.6477e-02],\n",
      "          [-5.9558e-03, -1.4507e-02, -1.4627e-02,  1.6131e-02],\n",
      "          [-8.7143e-03, -1.2595e-02, -1.1401e-02,  9.8681e-03]],\n",
      "\n",
      "         [[-3.7802e-03,  1.1201e-02, -1.6582e-02, -1.6931e-02],\n",
      "          [-1.3152e-02,  1.5645e-02,  9.4563e-03, -1.1212e-02],\n",
      "          [-8.4364e-03,  1.7261e-02, -7.6194e-03,  9.4539e-03],\n",
      "          [-2.5354e-03,  6.0194e-03, -1.9243e-02,  1.7186e-02]]]])\n",
      "------------------------\n",
      "Layer: gen.1.0.bias, Shape: torch.Size([128])\n",
      "Weights: tensor([-3.2516e-03,  1.3919e-02,  7.3777e-03,  4.1841e-05,  1.0131e-02,\n",
      "         1.6236e-02,  1.1876e-03, -7.5351e-04, -1.2150e-02, -9.1175e-03,\n",
      "         1.2810e-02,  7.3824e-04,  1.4975e-02,  1.7353e-02, -8.1183e-04,\n",
      "         1.0692e-02,  1.9952e-02,  1.7575e-02,  1.2425e-02, -1.5943e-02,\n",
      "        -1.7586e-03,  6.9316e-03,  1.1480e-02, -1.2180e-04,  1.2116e-02,\n",
      "        -1.6171e-03,  5.7706e-03, -1.6732e-02,  1.0744e-02, -7.1991e-03,\n",
      "        -1.7722e-02,  1.4888e-02,  2.4368e-03,  1.2949e-02,  7.6530e-03,\n",
      "         3.9160e-03, -1.3259e-02, -1.7129e-02,  1.8458e-02, -6.3456e-03,\n",
      "        -2.0844e-02, -9.2935e-03, -1.5458e-03,  1.5801e-02, -1.8407e-02,\n",
      "        -1.6377e-02,  2.7956e-03, -1.7799e-02,  1.4578e-02, -1.6889e-02,\n",
      "         1.3149e-02, -1.5887e-02,  5.5993e-03,  8.3170e-04,  1.1983e-02,\n",
      "         1.7674e-02,  1.8701e-02, -2.1721e-02,  1.0208e-03, -1.6099e-02,\n",
      "         1.1959e-02,  7.4811e-04,  2.0135e-02,  1.9400e-03, -4.7302e-03,\n",
      "        -3.2082e-03,  2.1884e-02, -6.9667e-03,  1.2723e-02, -1.0501e-02,\n",
      "        -1.5268e-02,  1.4709e-02,  5.1071e-03, -1.3428e-02, -7.3336e-03,\n",
      "         1.4718e-02,  7.4991e-04, -5.5782e-03,  1.8334e-02,  1.3022e-02,\n",
      "        -1.3139e-02,  6.9362e-03,  2.0657e-02,  1.2093e-02, -2.0467e-02,\n",
      "        -2.1320e-02, -2.3073e-03,  1.5320e-02, -1.2595e-02, -1.9922e-02,\n",
      "        -1.0208e-02,  1.2246e-02,  2.5942e-03,  1.7276e-02,  1.0530e-02,\n",
      "        -4.4473e-03, -1.9408e-02, -1.5777e-02, -5.4081e-03, -5.4282e-03,\n",
      "        -5.4377e-04, -1.7605e-02,  1.0629e-02,  2.1041e-02,  1.3790e-02,\n",
      "        -1.7928e-02,  8.0319e-03, -1.4043e-02, -2.8155e-03, -6.5350e-03,\n",
      "         5.9713e-03, -2.1009e-02, -1.1316e-02,  1.2113e-02,  9.0432e-03,\n",
      "         1.4043e-02,  2.5769e-03,  6.6504e-04, -1.8168e-02, -5.9220e-03,\n",
      "        -3.3161e-03,  3.8915e-03,  1.2654e-02, -1.3727e-02, -2.0243e-02,\n",
      "        -2.1401e-02,  1.3999e-02, -8.9770e-03])\n",
      "------------------------\n",
      "Layer: gen.1.1.weight, Shape: torch.Size([128])\n",
      "Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "------------------------\n",
      "Layer: gen.1.1.bias, Shape: torch.Size([128])\n",
      "Weights: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "------------------------\n",
      "Layer: gen.2.0.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Weights: tensor([[[[ 1.7490e-02, -3.9516e-02, -3.9322e-02],\n",
      "          [ 8.7718e-03,  2.2661e-02, -3.6703e-02],\n",
      "          [-4.0642e-02,  2.7875e-02,  1.4443e-02]],\n",
      "\n",
      "         [[-3.0831e-02,  2.0350e-02, -2.0234e-02],\n",
      "          [-3.0596e-02,  2.6667e-02,  3.6784e-02],\n",
      "          [ 2.2126e-02, -2.0667e-02,  7.0316e-03]],\n",
      "\n",
      "         [[-3.8363e-02, -3.4587e-02, -3.2981e-02],\n",
      "          [-1.7809e-02,  3.1006e-02,  1.4987e-02],\n",
      "          [-1.7014e-02, -2.3959e-02,  1.4610e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0431e-02, -2.8246e-03, -5.8538e-03],\n",
      "          [ 2.2036e-03,  5.4650e-03, -1.2456e-02],\n",
      "          [-1.4742e-02,  3.4327e-02, -3.8437e-02]],\n",
      "\n",
      "         [[-2.2398e-02,  2.4244e-02, -2.7181e-02],\n",
      "          [ 2.8156e-02,  2.0576e-03,  1.3257e-02],\n",
      "          [ 9.1537e-04, -1.3752e-02,  4.1616e-02]],\n",
      "\n",
      "         [[ 2.7909e-02, -1.2479e-02, -9.1374e-03],\n",
      "          [-3.1381e-02, -9.7282e-03, -3.9652e-02],\n",
      "          [ 3.8829e-02, -2.1508e-02,  2.5813e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9493e-03, -2.2376e-02, -1.7700e-02],\n",
      "          [ 3.7318e-02, -2.5695e-02, -1.1169e-02],\n",
      "          [ 3.6352e-02,  2.1383e-02,  2.5240e-02]],\n",
      "\n",
      "         [[-2.9004e-02,  5.5189e-03, -6.9596e-03],\n",
      "          [ 2.6600e-02, -3.9669e-02, -1.0466e-02],\n",
      "          [ 2.2293e-02, -3.3630e-02, -8.4319e-03]],\n",
      "\n",
      "         [[ 3.7171e-02,  1.2979e-02, -1.4193e-02],\n",
      "          [ 2.8099e-02, -3.9301e-02, -2.4041e-02],\n",
      "          [ 1.5024e-02, -2.0348e-02, -2.7906e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1811e-02, -3.9110e-02,  2.1799e-02],\n",
      "          [-4.1157e-02, -3.2313e-02, -1.1933e-02],\n",
      "          [-1.8812e-02,  1.5901e-03, -1.4844e-02]],\n",
      "\n",
      "         [[ 8.5727e-04, -1.7586e-02, -2.9810e-02],\n",
      "          [ 2.1504e-02, -2.3829e-02,  8.2842e-03],\n",
      "          [-2.2655e-02, -3.3074e-02, -1.2370e-02]],\n",
      "\n",
      "         [[ 3.3120e-02,  2.4726e-02,  1.9185e-02],\n",
      "          [ 3.2827e-02, -3.0774e-02,  3.7930e-02],\n",
      "          [-1.4675e-02, -2.8672e-02, -2.1234e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8608e-02, -1.4401e-03,  3.9160e-02],\n",
      "          [ 3.9132e-02, -4.1290e-02,  6.8913e-03],\n",
      "          [-4.3283e-03, -3.9664e-02,  2.7498e-03]],\n",
      "\n",
      "         [[-2.8060e-04, -1.3754e-02,  2.7248e-02],\n",
      "          [-9.6372e-03, -8.0642e-03, -3.1858e-02],\n",
      "          [ 1.1996e-02,  1.5734e-03,  8.1766e-03]],\n",
      "\n",
      "         [[ 2.6277e-02, -1.7186e-02, -2.6557e-02],\n",
      "          [ 2.7945e-02, -2.4976e-02, -3.4301e-02],\n",
      "          [ 8.8562e-03,  2.3099e-02,  3.0018e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1057e-02, -2.3037e-02,  2.6674e-03],\n",
      "          [ 3.0908e-02, -1.1007e-02, -4.0986e-02],\n",
      "          [-5.0598e-03, -5.8920e-03, -3.7405e-02]],\n",
      "\n",
      "         [[ 1.7059e-02, -6.4446e-03,  3.6843e-02],\n",
      "          [-3.5970e-03,  1.4994e-02, -3.8295e-02],\n",
      "          [ 1.1338e-02, -3.2862e-02, -2.0841e-02]],\n",
      "\n",
      "         [[ 2.5927e-02, -1.3660e-02, -3.1844e-02],\n",
      "          [ 2.3099e-02,  3.6381e-02,  1.5089e-02],\n",
      "          [-2.8250e-03, -7.5448e-03,  4.1033e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.3296e-03,  3.7842e-03,  3.6246e-02],\n",
      "          [ 1.9931e-02, -2.0317e-03, -1.4251e-02],\n",
      "          [ 2.6290e-02, -2.1399e-02,  2.4172e-02]],\n",
      "\n",
      "         [[ 2.4299e-02, -1.8226e-02, -1.0326e-02],\n",
      "          [-3.2025e-02, -3.6448e-02,  3.8950e-02],\n",
      "          [-1.7946e-02, -5.5482e-03,  3.9963e-02]],\n",
      "\n",
      "         [[-2.6202e-02, -3.6274e-02,  1.0606e-02],\n",
      "          [ 1.7027e-02, -2.7497e-02,  1.8027e-02],\n",
      "          [-3.5664e-02,  3.4419e-02, -3.5592e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2328e-03,  2.6177e-02,  2.8090e-02],\n",
      "          [-3.6658e-02,  9.7958e-03,  3.1350e-02],\n",
      "          [ 1.9992e-02,  3.6451e-02, -3.8100e-02]],\n",
      "\n",
      "         [[-3.1978e-04, -7.7560e-03,  2.9634e-03],\n",
      "          [ 3.2004e-02, -3.9121e-02, -3.5225e-02],\n",
      "          [ 1.9067e-02, -3.5425e-02, -2.9025e-02]],\n",
      "\n",
      "         [[ 3.4714e-02,  3.6551e-02,  7.4732e-03],\n",
      "          [ 4.1459e-02, -3.0892e-02,  2.2196e-02],\n",
      "          [-2.4383e-02,  3.7780e-02,  2.7386e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0046e-02, -1.3792e-02,  2.2633e-02],\n",
      "          [ 5.3794e-03, -3.0179e-03, -8.8226e-03],\n",
      "          [-1.4298e-02,  2.3858e-03,  2.8659e-02]],\n",
      "\n",
      "         [[ 3.8958e-02,  1.9289e-02,  3.6307e-02],\n",
      "          [ 7.9111e-03,  2.5076e-02, -1.5806e-03],\n",
      "          [-2.0609e-02, -3.3282e-03, -1.8498e-02]],\n",
      "\n",
      "         [[-4.0837e-02, -1.4547e-02,  5.5779e-03],\n",
      "          [ 5.8532e-04,  3.7027e-02,  2.0475e-02],\n",
      "          [ 5.5456e-03, -1.9899e-02,  2.4200e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1433e-02,  4.2378e-03, -3.5589e-02],\n",
      "          [-1.4152e-02, -1.9709e-02, -2.3388e-02],\n",
      "          [ 9.9589e-06, -3.0251e-02, -3.8325e-02]],\n",
      "\n",
      "         [[-3.9177e-02, -1.9991e-02,  3.2947e-02],\n",
      "          [ 2.8321e-02,  1.7081e-02,  7.4002e-03],\n",
      "          [ 8.6599e-03, -7.4150e-03, -1.1380e-02]],\n",
      "\n",
      "         [[ 1.9246e-02,  3.6012e-02, -2.8071e-02],\n",
      "          [-2.8234e-02, -3.0274e-02, -1.9679e-02],\n",
      "          [-5.4458e-03,  1.3540e-02, -1.5278e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5827e-02, -2.6094e-02, -3.4798e-02],\n",
      "          [-3.9203e-02,  7.3145e-03,  1.1574e-02],\n",
      "          [ 1.6465e-02, -4.1117e-02, -3.7936e-02]],\n",
      "\n",
      "         [[-9.5117e-03,  3.5725e-02, -3.9137e-02],\n",
      "          [-8.8737e-03,  9.1529e-04, -2.7463e-02],\n",
      "          [ 2.7312e-02, -2.9033e-03, -5.0007e-03]],\n",
      "\n",
      "         [[ 1.6129e-03,  1.5701e-02,  3.5873e-02],\n",
      "          [ 3.8636e-02,  2.1169e-02, -1.7824e-02],\n",
      "          [ 1.7455e-02,  2.8923e-02, -2.5730e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9521e-02, -7.6663e-03, -1.9425e-02],\n",
      "          [ 1.9171e-02,  2.1915e-02,  3.5459e-02],\n",
      "          [-2.2494e-02, -1.9122e-02,  3.4562e-02]],\n",
      "\n",
      "         [[-1.7961e-03, -4.0922e-02,  1.1953e-02],\n",
      "          [ 3.2828e-02, -1.3984e-02,  3.3274e-02],\n",
      "          [-2.9207e-03, -2.8692e-02,  1.2406e-02]],\n",
      "\n",
      "         [[-4.0892e-02, -5.8780e-03,  8.4638e-03],\n",
      "          [-3.6079e-02,  3.2584e-02, -4.7390e-03],\n",
      "          [-1.8618e-02, -5.1311e-03,  2.7422e-02]]]])\n",
      "------------------------\n",
      "Layer: gen.2.0.bias, Shape: torch.Size([64])\n",
      "Weights: tensor([-0.0370,  0.0073, -0.0136,  0.0034, -0.0011, -0.0222,  0.0339, -0.0399,\n",
      "        -0.0236,  0.0185, -0.0196, -0.0305,  0.0139,  0.0022,  0.0155, -0.0165,\n",
      "        -0.0037, -0.0022, -0.0227,  0.0026, -0.0299,  0.0177,  0.0003, -0.0384,\n",
      "        -0.0162, -0.0378, -0.0087, -0.0353,  0.0403, -0.0360, -0.0367, -0.0263,\n",
      "        -0.0082, -0.0098,  0.0093,  0.0404,  0.0153,  0.0408,  0.0378,  0.0225,\n",
      "        -0.0036, -0.0195, -0.0352, -0.0374, -0.0053, -0.0225, -0.0026, -0.0285,\n",
      "         0.0017, -0.0216,  0.0064,  0.0346,  0.0109, -0.0104,  0.0176, -0.0289,\n",
      "        -0.0172,  0.0109, -0.0411,  0.0263,  0.0124, -0.0279,  0.0112,  0.0044])\n",
      "------------------------\n",
      "Layer: gen.2.1.weight, Shape: torch.Size([64])\n",
      "Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "------------------------\n",
      "Layer: gen.2.1.bias, Shape: torch.Size([64])\n",
      "Weights: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "------------------------\n",
      "Layer: gen.3.0.weight, Shape: torch.Size([64, 1, 4, 4])\n",
      "Weights: tensor([[[[ 0.2272, -0.1883,  0.1776, -0.1681],\n",
      "          [-0.2205, -0.1710, -0.1314,  0.0597],\n",
      "          [ 0.1397, -0.1517, -0.2047,  0.0496],\n",
      "          [-0.2466,  0.1933,  0.2059, -0.1161]]],\n",
      "\n",
      "\n",
      "        [[[-0.1861,  0.0417, -0.0457, -0.1448],\n",
      "          [ 0.0505,  0.2055,  0.1292, -0.0424],\n",
      "          [-0.1523, -0.2104,  0.0453,  0.1251],\n",
      "          [ 0.0923,  0.1717, -0.0454,  0.2018]]],\n",
      "\n",
      "\n",
      "        [[[-0.1149,  0.0988,  0.0164,  0.2086],\n",
      "          [ 0.0959,  0.1304, -0.0194, -0.0715],\n",
      "          [ 0.0715, -0.1030, -0.1515,  0.1355],\n",
      "          [ 0.0320,  0.0496, -0.1537,  0.1996]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0855, -0.0949,  0.2373,  0.1073],\n",
      "          [ 0.1570, -0.0830,  0.0441, -0.0113],\n",
      "          [-0.1339,  0.1134, -0.0912,  0.1104],\n",
      "          [-0.0292, -0.2140, -0.1179,  0.0612]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1668,  0.0535, -0.0981,  0.1554],\n",
      "          [ 0.2277, -0.0666, -0.0998,  0.0431],\n",
      "          [-0.2445,  0.2196,  0.1847, -0.1604],\n",
      "          [ 0.0744, -0.2193, -0.2132,  0.1805]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1691,  0.0394,  0.0437,  0.1739],\n",
      "          [ 0.1846,  0.2171,  0.2240, -0.1885],\n",
      "          [-0.2292,  0.1113, -0.1019,  0.0617],\n",
      "          [ 0.2088, -0.0539,  0.1714,  0.0944]]]])\n",
      "------------------------\n",
      "Layer: gen.3.0.bias, Shape: torch.Size([1])\n",
      "Weights: tensor([-0.0845])\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for name,param in gen.named_parameters():\n",
    "    print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "    print(f\"Weights: {param.data}\")\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: disc.0.0.weight, Shape: torch.Size([16, 1, 4, 4])\n",
      "Weights: tensor([[[[-0.0403,  0.0440, -0.0335, -0.1113],\n",
      "          [ 0.0083,  0.1338,  0.1373, -0.2130],\n",
      "          [-0.1689, -0.2096, -0.0192,  0.1718],\n",
      "          [ 0.1190, -0.0886, -0.1593,  0.2088]]],\n",
      "\n",
      "\n",
      "        [[[-0.0764, -0.1671,  0.0562, -0.0343],\n",
      "          [-0.1469, -0.0002,  0.0489, -0.1772],\n",
      "          [-0.0427, -0.0194, -0.2379, -0.1717],\n",
      "          [ 0.0862,  0.0283, -0.1430,  0.2044]]],\n",
      "\n",
      "\n",
      "        [[[-0.2150, -0.1366,  0.0973,  0.1678],\n",
      "          [-0.0757,  0.1509,  0.0369, -0.1726],\n",
      "          [ 0.0536,  0.0619,  0.0581,  0.0506],\n",
      "          [-0.0970,  0.2196,  0.0881,  0.0030]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1918, -0.1116,  0.2268,  0.1138],\n",
      "          [-0.0593, -0.1087, -0.1400, -0.1937],\n",
      "          [ 0.0628, -0.1781,  0.0489, -0.2010],\n",
      "          [ 0.0582, -0.2280, -0.1881, -0.0052]]],\n",
      "\n",
      "\n",
      "        [[[-0.0212, -0.1425,  0.0697,  0.0083],\n",
      "          [ 0.0377, -0.1528,  0.1925, -0.1450],\n",
      "          [ 0.2151, -0.0091, -0.1832, -0.0175],\n",
      "          [ 0.1826,  0.1415, -0.0914,  0.1487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1192, -0.2343,  0.0477,  0.1342],\n",
      "          [ 0.0146, -0.0284,  0.0939, -0.1972],\n",
      "          [-0.1819, -0.2117,  0.1519,  0.0675],\n",
      "          [ 0.2284, -0.2162,  0.0781, -0.1017]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1916, -0.1404, -0.1296,  0.2424],\n",
      "          [ 0.1623,  0.0501,  0.0586, -0.1912],\n",
      "          [ 0.2167, -0.1391,  0.0197,  0.0858],\n",
      "          [-0.1705,  0.0636,  0.1982,  0.0581]]],\n",
      "\n",
      "\n",
      "        [[[-0.0009,  0.1239, -0.2041,  0.0514],\n",
      "          [-0.0476,  0.0652, -0.1009, -0.2131],\n",
      "          [ 0.0581, -0.0091, -0.0423, -0.0186],\n",
      "          [ 0.1363, -0.1357,  0.2109,  0.1652]]],\n",
      "\n",
      "\n",
      "        [[[-0.0298,  0.1537, -0.1750,  0.0144],\n",
      "          [-0.0620, -0.2437, -0.1170, -0.1397],\n",
      "          [-0.0373, -0.1271,  0.1798, -0.1298],\n",
      "          [-0.1689,  0.0491, -0.0851, -0.1564]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1529,  0.0904, -0.1514, -0.0327],\n",
      "          [-0.2339, -0.0273,  0.0285, -0.0427],\n",
      "          [ 0.0451,  0.2240, -0.2374, -0.2189],\n",
      "          [-0.1209, -0.1599,  0.1441,  0.0083]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0631, -0.1088,  0.1419, -0.0882],\n",
      "          [ 0.1224,  0.1943, -0.1392, -0.0658],\n",
      "          [ 0.0525, -0.2080,  0.1625,  0.2132],\n",
      "          [-0.1920, -0.0442,  0.1572,  0.1745]]],\n",
      "\n",
      "\n",
      "        [[[-0.1276,  0.2007,  0.2241,  0.1589],\n",
      "          [ 0.0352, -0.1079,  0.1492, -0.0283],\n",
      "          [ 0.0296,  0.0236, -0.2391, -0.1028],\n",
      "          [ 0.2089, -0.1959,  0.1901, -0.0500]]],\n",
      "\n",
      "\n",
      "        [[[-0.1123,  0.1548,  0.2135, -0.0047],\n",
      "          [ 0.2433, -0.2253,  0.1961,  0.1556],\n",
      "          [-0.1156,  0.0230, -0.1455,  0.0438],\n",
      "          [-0.1747, -0.1427, -0.2429,  0.1989]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0177, -0.1483,  0.1370,  0.2126],\n",
      "          [-0.1950,  0.2038,  0.2016,  0.0601],\n",
      "          [ 0.2440,  0.0293,  0.0753, -0.1881],\n",
      "          [ 0.0115,  0.1424,  0.0187,  0.0525]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0793, -0.0806,  0.1748,  0.1623],\n",
      "          [-0.0194, -0.0966,  0.0265, -0.0438],\n",
      "          [-0.0226, -0.2119, -0.0775,  0.1328],\n",
      "          [-0.1180, -0.2303,  0.0626, -0.1740]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1445, -0.1020,  0.0210, -0.2146],\n",
      "          [-0.1666, -0.0723,  0.1684,  0.0262],\n",
      "          [-0.0719,  0.1543, -0.1433,  0.1362],\n",
      "          [ 0.0162, -0.1188,  0.0438,  0.1398]]]])\n",
      "------------------------\n",
      "Layer: disc.0.0.bias, Shape: torch.Size([16])\n",
      "Weights: tensor([ 0.2241,  0.0740, -0.2407, -0.0582,  0.1853,  0.0250, -0.1323, -0.1858,\n",
      "        -0.0481, -0.1005,  0.1108,  0.2184,  0.1954,  0.1086,  0.1206,  0.2309])\n",
      "------------------------\n",
      "Layer: disc.0.1.weight, Shape: torch.Size([16])\n",
      "Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "------------------------\n",
      "Layer: disc.0.1.bias, Shape: torch.Size([16])\n",
      "Weights: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "------------------------\n",
      "Layer: disc.1.0.weight, Shape: torch.Size([32, 16, 4, 4])\n",
      "Weights: tensor([[[[ 1.8317e-02,  2.5729e-02,  1.6311e-02, -3.2905e-02],\n",
      "          [-2.4327e-02, -2.3556e-03,  4.0431e-03,  6.0839e-02],\n",
      "          [-1.7963e-02, -1.8043e-02, -5.2608e-02,  3.6930e-02],\n",
      "          [ 3.5053e-02, -4.7840e-02, -4.9447e-02,  2.7227e-02]],\n",
      "\n",
      "         [[ 5.4646e-02, -4.0061e-03,  1.9065e-02, -2.2108e-02],\n",
      "          [-5.1464e-02,  3.5727e-02,  2.7799e-02,  8.2403e-03],\n",
      "          [-1.7149e-02,  5.5571e-02,  2.2581e-02,  3.1314e-02],\n",
      "          [ 1.4495e-02,  3.1398e-02,  5.2096e-03,  5.8425e-02]],\n",
      "\n",
      "         [[-2.5373e-02, -2.4378e-02,  1.9509e-02,  5.9380e-02],\n",
      "          [ 3.1803e-02,  1.1496e-02, -5.5584e-02,  1.5729e-02],\n",
      "          [-5.6776e-02,  5.0057e-02,  1.4495e-02,  2.7779e-02],\n",
      "          [-5.0209e-02,  3.6402e-02,  4.2498e-02, -3.2142e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0004e-02, -5.9135e-02, -8.5493e-03, -5.2973e-02],\n",
      "          [-2.4343e-02,  2.7047e-02,  3.2439e-02,  5.1112e-02],\n",
      "          [ 4.9643e-02, -1.9998e-02, -1.3843e-02, -5.5472e-04],\n",
      "          [-5.2509e-02,  3.8081e-02, -4.4195e-02,  1.9973e-02]],\n",
      "\n",
      "         [[ 4.4743e-02, -5.1462e-02,  1.7003e-02,  6.1216e-02],\n",
      "          [-1.1858e-02, -4.1200e-02,  5.9391e-02, -3.9263e-02],\n",
      "          [ 5.8682e-02, -4.1398e-03,  9.1346e-04,  9.5829e-05],\n",
      "          [ 1.7276e-03, -1.0054e-02,  1.9695e-03, -4.2115e-02]],\n",
      "\n",
      "         [[-2.1643e-02,  3.7920e-02, -1.7111e-02, -4.3321e-02],\n",
      "          [-4.8537e-02, -5.4258e-02,  3.1357e-02,  4.0248e-02],\n",
      "          [ 6.6800e-04, -8.5808e-03,  5.0459e-02,  3.3908e-02],\n",
      "          [ 4.2634e-02, -3.5811e-02, -3.0034e-02, -3.0297e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.9302e-03,  3.8338e-02,  4.8313e-02,  1.1109e-02],\n",
      "          [ 8.4178e-03, -5.5560e-02, -2.9670e-02,  8.7955e-03],\n",
      "          [ 2.9008e-02,  4.6320e-02,  7.7851e-03,  3.4854e-03],\n",
      "          [-3.6815e-02, -3.0700e-02,  5.8204e-02,  5.4213e-02]],\n",
      "\n",
      "         [[-1.0602e-05,  7.9780e-03,  4.9037e-02,  1.3555e-02],\n",
      "          [ 6.1448e-02,  2.2442e-02,  1.9245e-03, -5.4245e-02],\n",
      "          [-5.2859e-03, -1.7421e-04,  2.1922e-02, -2.4781e-02],\n",
      "          [-4.6387e-02, -2.4262e-02,  6.1367e-02, -1.9617e-02]],\n",
      "\n",
      "         [[ 6.1814e-02,  1.4823e-02,  2.3595e-02,  1.5443e-02],\n",
      "          [-6.2335e-02, -1.1021e-02,  6.1443e-02, -5.9362e-02],\n",
      "          [ 2.3811e-02,  5.8061e-02, -1.6057e-02,  5.7739e-04],\n",
      "          [ 4.4251e-02,  1.3676e-02,  3.2546e-03, -4.1275e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6583e-02,  4.6606e-02,  2.8308e-02,  2.2507e-02],\n",
      "          [ 4.6566e-02, -4.5802e-02,  5.0862e-02,  3.5238e-02],\n",
      "          [ 6.1287e-02, -1.2745e-02,  2.8510e-02,  5.8235e-02],\n",
      "          [ 1.3228e-02,  2.5498e-02,  1.7496e-02, -5.6076e-02]],\n",
      "\n",
      "         [[ 4.9828e-02, -6.7088e-03, -2.0467e-02, -3.3561e-02],\n",
      "          [ 3.0340e-03,  4.1066e-03, -2.1727e-02,  5.1632e-02],\n",
      "          [ 3.0432e-02, -5.2006e-02,  5.6653e-02, -1.3732e-02],\n",
      "          [-2.5900e-02, -1.6914e-02,  3.6697e-02, -5.2091e-02]],\n",
      "\n",
      "         [[ 2.5471e-02, -5.3861e-02,  3.5741e-02, -3.7033e-03],\n",
      "          [-1.9640e-02, -5.2711e-02, -5.9446e-02,  5.6542e-03],\n",
      "          [-2.9775e-02, -6.0432e-02,  4.1165e-02,  4.9559e-02],\n",
      "          [-4.7018e-02,  2.5802e-02, -4.7832e-02,  5.4876e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2509e-02, -5.5847e-02, -5.5756e-02,  4.5025e-02],\n",
      "          [ 4.3706e-02, -1.3666e-02, -5.4291e-02,  6.1221e-02],\n",
      "          [ 9.9103e-03, -1.1625e-02,  4.3575e-02,  1.7791e-03],\n",
      "          [ 2.0332e-02, -3.5064e-03,  2.2962e-02, -1.0843e-02]],\n",
      "\n",
      "         [[-3.9481e-02, -3.5395e-03,  8.6117e-03, -1.2141e-02],\n",
      "          [ 4.0309e-02,  5.4118e-02,  2.1698e-02,  6.1204e-02],\n",
      "          [ 4.6071e-02,  4.1565e-02, -8.2980e-03, -3.3788e-02],\n",
      "          [-2.5003e-02,  5.2043e-02,  1.5656e-02,  6.0217e-02]],\n",
      "\n",
      "         [[-4.1132e-02,  4.9525e-03,  1.4075e-02, -5.5816e-02],\n",
      "          [ 3.6130e-02, -2.9320e-02, -5.2801e-03,  5.7888e-02],\n",
      "          [-3.1491e-02, -1.0592e-03, -1.6208e-02, -4.6792e-02],\n",
      "          [ 4.0524e-02, -2.1783e-02,  1.2722e-02,  5.7916e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3937e-02,  4.2891e-02,  3.5681e-02,  3.4207e-02],\n",
      "          [ 4.6041e-02,  1.5485e-02,  4.6661e-02, -3.0932e-02],\n",
      "          [-2.2967e-02, -2.9380e-02,  1.1804e-03, -2.2373e-02],\n",
      "          [-1.1568e-03, -6.0016e-02,  2.7864e-02, -1.4473e-02]],\n",
      "\n",
      "         [[ 1.6494e-02,  4.1135e-02,  3.8914e-02,  1.9695e-02],\n",
      "          [ 2.9706e-02, -2.0372e-02,  2.8394e-02,  2.0716e-02],\n",
      "          [-3.9470e-02, -3.0807e-02, -6.1388e-02,  5.7752e-02],\n",
      "          [ 4.5878e-03, -5.0932e-02,  3.7128e-03,  2.3382e-02]],\n",
      "\n",
      "         [[ 4.5638e-02,  6.0543e-02, -2.7013e-02,  1.8278e-02],\n",
      "          [-4.7953e-02, -5.9389e-02, -3.8932e-02, -3.0930e-03],\n",
      "          [ 5.4232e-02,  8.4546e-03,  5.4998e-02, -1.4546e-02],\n",
      "          [-2.6594e-02, -3.8280e-02, -1.1344e-02, -2.2128e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.2489e-02,  1.5233e-02, -2.7910e-02, -4.6396e-02],\n",
      "          [ 1.6393e-02, -2.6506e-02, -2.6532e-02,  3.5788e-02],\n",
      "          [ 5.6383e-02,  5.6268e-02,  1.7932e-02, -2.9534e-02],\n",
      "          [-5.2584e-02,  4.2886e-02, -2.8274e-02, -2.6536e-02]],\n",
      "\n",
      "         [[-4.6804e-03, -4.3121e-02, -6.0365e-02,  4.8723e-02],\n",
      "          [ 5.2321e-02,  1.0184e-02,  1.1578e-02,  4.7647e-02],\n",
      "          [-5.3755e-02,  4.7582e-02, -3.4039e-03,  3.1452e-02],\n",
      "          [ 5.0482e-02, -5.7437e-02,  1.8386e-02,  5.3346e-02]],\n",
      "\n",
      "         [[-4.2162e-02,  1.4103e-02, -1.9269e-02, -1.8095e-02],\n",
      "          [-1.8104e-02, -4.0645e-02,  6.0102e-03,  3.0322e-02],\n",
      "          [-2.4530e-02,  4.4744e-02, -7.3746e-05,  5.8158e-02],\n",
      "          [ 1.8407e-02,  7.2115e-03,  4.1076e-02,  6.1653e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5481e-02, -1.9875e-02, -3.6337e-02, -9.7978e-03],\n",
      "          [-3.4580e-03, -3.8960e-02, -5.2834e-04, -5.8775e-02],\n",
      "          [ 1.4539e-02, -1.7474e-02,  3.3196e-02, -2.1388e-02],\n",
      "          [-2.3181e-02,  5.3089e-02, -3.0994e-02, -4.6001e-02]],\n",
      "\n",
      "         [[-4.1342e-02,  4.1937e-02, -4.2307e-02, -3.2169e-04],\n",
      "          [ 4.8403e-02, -4.8633e-02, -1.0296e-02, -3.0052e-02],\n",
      "          [-2.6582e-03,  4.3814e-03,  3.9400e-02,  2.0292e-02],\n",
      "          [ 1.5751e-02, -3.8329e-02,  2.1268e-02, -5.8450e-02]],\n",
      "\n",
      "         [[-2.5732e-02,  4.6510e-02, -4.5373e-02,  3.7636e-02],\n",
      "          [-4.1643e-02, -4.8537e-02,  1.2449e-02,  5.3627e-02],\n",
      "          [ 1.2250e-02,  4.6361e-03,  8.4252e-03, -5.3639e-02],\n",
      "          [ 5.9216e-02, -3.1576e-02, -1.7126e-02,  5.5642e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8310e-02,  1.2111e-02, -2.9743e-02, -1.7308e-02],\n",
      "          [-3.9270e-02,  4.9597e-02,  3.1866e-02,  2.3733e-02],\n",
      "          [-5.7199e-02,  1.0401e-02,  7.0033e-03,  5.8768e-02],\n",
      "          [ 4.4483e-02, -1.6132e-02,  2.5088e-03, -1.9715e-02]],\n",
      "\n",
      "         [[-4.8928e-02, -2.3226e-02,  1.7355e-02,  5.6479e-02],\n",
      "          [ 6.1838e-02,  4.0228e-02, -4.4896e-02, -3.2786e-02],\n",
      "          [ 2.0129e-02, -1.0150e-02, -8.1626e-03, -5.2577e-02],\n",
      "          [-6.0330e-02, -6.0969e-02,  4.9735e-02, -4.4301e-02]],\n",
      "\n",
      "         [[ 5.0491e-02,  2.0453e-02, -1.5408e-02, -5.0484e-02],\n",
      "          [-1.2434e-02, -4.1213e-03,  3.7118e-02, -3.5512e-02],\n",
      "          [-4.0425e-02, -2.7346e-02, -4.0521e-02, -4.6382e-02],\n",
      "          [-2.8939e-02, -4.4681e-02, -1.9155e-03,  5.8801e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8144e-02, -1.0212e-02, -4.3889e-02,  3.4252e-03],\n",
      "          [-2.7000e-02,  4.6115e-02,  4.6418e-02,  6.1052e-02],\n",
      "          [-4.9491e-02,  4.2803e-02,  4.9137e-02,  3.8663e-02],\n",
      "          [ 5.7827e-02, -4.9637e-02,  4.2918e-02, -5.3077e-02]],\n",
      "\n",
      "         [[-3.8212e-02, -2.7274e-02, -5.7174e-02,  5.6418e-02],\n",
      "          [-3.6975e-02,  4.3744e-02, -5.2609e-02,  1.3808e-02],\n",
      "          [ 2.1895e-02, -2.0348e-02,  2.8028e-02,  3.9709e-02],\n",
      "          [-4.2832e-03, -1.0365e-02,  4.3366e-02,  3.8906e-02]],\n",
      "\n",
      "         [[ 1.2435e-02,  2.6306e-03, -1.2807e-02,  4.6363e-02],\n",
      "          [-4.3680e-03,  8.8591e-03,  1.2810e-02, -4.1411e-02],\n",
      "          [-7.5232e-03, -5.3865e-03, -1.1377e-02, -1.3633e-02],\n",
      "          [ 3.9553e-02,  3.0082e-02,  5.9068e-02,  5.3675e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7015e-02,  3.2539e-02,  6.0245e-02, -5.7129e-02],\n",
      "          [-1.4025e-02,  1.3824e-02,  1.5078e-02, -4.1928e-02],\n",
      "          [-5.0741e-02, -2.0231e-02,  5.4131e-02, -1.5492e-02],\n",
      "          [-2.2838e-04, -5.1011e-02,  4.3568e-02,  1.8995e-02]],\n",
      "\n",
      "         [[-2.9077e-02,  5.2250e-02, -4.0164e-02,  2.6377e-02],\n",
      "          [-4.3196e-02, -2.5688e-02,  5.0059e-02, -1.7383e-02],\n",
      "          [-3.0389e-02, -1.0948e-02, -1.9675e-02,  4.2027e-03],\n",
      "          [ 5.6516e-02,  9.3765e-03, -4.8554e-02, -5.3563e-02]],\n",
      "\n",
      "         [[-2.3405e-02, -8.4961e-03,  2.6444e-02, -2.9176e-02],\n",
      "          [ 1.1627e-02, -4.8847e-02, -5.1711e-02,  5.1986e-02],\n",
      "          [ 3.8368e-02,  2.1746e-02, -6.6297e-04,  3.7490e-02],\n",
      "          [-2.1769e-03, -1.2507e-02,  9.5430e-04, -2.1436e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9470e-02, -9.5610e-03, -4.2849e-02,  9.5544e-03],\n",
      "          [ 4.9336e-02, -2.0446e-02,  4.6305e-02,  2.7667e-02],\n",
      "          [-5.3205e-02,  5.8246e-02,  5.4020e-02,  5.5810e-02],\n",
      "          [ 3.8296e-02,  1.5595e-02,  4.5620e-02,  4.3635e-02]],\n",
      "\n",
      "         [[ 4.1744e-02,  5.9724e-02, -9.0096e-03, -3.9765e-02],\n",
      "          [ 2.5910e-02,  1.2665e-02, -2.9922e-02,  1.7269e-02],\n",
      "          [-1.0420e-02, -3.9745e-02,  3.3977e-02,  5.8897e-02],\n",
      "          [ 4.4842e-02, -1.3396e-02,  6.0384e-02, -3.4091e-02]],\n",
      "\n",
      "         [[ 1.6015e-02, -2.4940e-02, -5.0309e-02, -6.9306e-03],\n",
      "          [ 4.7441e-02, -3.8039e-02,  5.1561e-02,  4.0326e-02],\n",
      "          [-2.0875e-02,  1.5026e-02, -3.7267e-02,  5.6238e-02],\n",
      "          [ 5.8016e-02, -3.3894e-02,  5.3763e-02, -5.1097e-02]]]])\n",
      "------------------------\n",
      "Layer: disc.1.0.bias, Shape: torch.Size([32])\n",
      "Weights: tensor([-0.0511,  0.0322,  0.0025, -0.0438,  0.0229, -0.0578,  0.0288,  0.0599,\n",
      "         0.0552,  0.0465, -0.0144,  0.0554, -0.0213, -0.0282, -0.0067, -0.0219,\n",
      "        -0.0478, -0.0070, -0.0314, -0.0041,  0.0106, -0.0552, -0.0248,  0.0409,\n",
      "         0.0367,  0.0008,  0.0007,  0.0033, -0.0310,  0.0533,  0.0293,  0.0384])\n",
      "------------------------\n",
      "Layer: disc.1.1.weight, Shape: torch.Size([32])\n",
      "Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "------------------------\n",
      "Layer: disc.1.1.bias, Shape: torch.Size([32])\n",
      "Weights: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "------------------------\n",
      "Layer: disc.2.0.weight, Shape: torch.Size([1, 32, 4, 4])\n",
      "Weights: tensor([[[[ 2.1251e-02,  6.5838e-03, -2.0281e-02,  1.2148e-02],\n",
      "          [ 5.1749e-03,  4.1330e-02,  3.3232e-02, -3.0740e-02],\n",
      "          [-3.8859e-02, -6.0643e-03, -3.0420e-02,  7.6116e-03],\n",
      "          [-1.3673e-02, -3.7934e-02, -2.8232e-02, -2.0358e-02]],\n",
      "\n",
      "         [[-2.1610e-02, -1.6682e-02, -3.7594e-02, -1.5785e-02],\n",
      "          [ 3.0137e-02,  4.7911e-03,  2.6241e-02, -2.5958e-02],\n",
      "          [ 1.7828e-02, -2.4254e-02,  1.7610e-02,  2.5368e-02],\n",
      "          [-1.3937e-02, -3.6900e-02,  1.7762e-02,  2.1828e-02]],\n",
      "\n",
      "         [[ 4.7095e-03,  3.2274e-02,  2.7154e-02, -2.8535e-02],\n",
      "          [-9.8037e-04,  9.0384e-03, -2.7708e-02,  3.5003e-02],\n",
      "          [ 3.8030e-02,  1.0286e-02,  3.1993e-02,  4.1995e-02],\n",
      "          [ 3.0250e-02,  3.9315e-02, -3.5027e-02,  7.0856e-03]],\n",
      "\n",
      "         [[-3.4617e-02, -3.5104e-03,  7.0254e-03, -6.1690e-03],\n",
      "          [ 1.1411e-02,  8.6534e-03,  4.0266e-02, -3.4332e-02],\n",
      "          [-9.6371e-03, -3.3344e-02, -3.5278e-02, -3.8722e-02],\n",
      "          [ 3.7169e-02,  2.4083e-02, -5.5988e-03,  1.5347e-02]],\n",
      "\n",
      "         [[ 9.8542e-03,  2.5621e-02,  7.7251e-04, -1.2594e-02],\n",
      "          [ 1.4230e-02,  2.2941e-02,  4.2549e-02, -4.0872e-02],\n",
      "          [-2.4440e-02,  2.3397e-02,  2.7210e-02,  4.8640e-03],\n",
      "          [ 5.2423e-03,  3.0657e-02,  3.3567e-02, -3.5133e-02]],\n",
      "\n",
      "         [[-7.5011e-05, -1.0928e-02, -1.2142e-03,  2.0555e-02],\n",
      "          [-4.1226e-02, -2.8028e-02,  1.6235e-02, -1.3895e-03],\n",
      "          [ 6.2199e-03, -3.4480e-02,  2.3871e-02, -1.1201e-02],\n",
      "          [ 8.6111e-03, -4.2491e-02,  1.9501e-02,  3.3798e-02]],\n",
      "\n",
      "         [[-3.7458e-02,  3.8776e-02,  7.5794e-03,  6.1718e-04],\n",
      "          [-1.7019e-02,  2.4079e-02,  3.4383e-02, -4.1598e-03],\n",
      "          [ 8.8513e-03,  3.2428e-02, -4.0904e-02, -6.0852e-03],\n",
      "          [ 3.3635e-02,  5.5493e-03,  8.6084e-03, -1.4603e-03]],\n",
      "\n",
      "         [[-3.2766e-03,  3.2019e-02, -6.9125e-03, -2.5653e-02],\n",
      "          [ 8.4957e-03, -7.2059e-03, -2.8023e-02, -4.1435e-02],\n",
      "          [-3.8295e-02,  2.9881e-02, -4.2690e-02, -2.8441e-02],\n",
      "          [ 2.9694e-02,  2.9101e-02,  1.8410e-02, -4.3969e-02]],\n",
      "\n",
      "         [[-4.0977e-02,  6.4833e-03,  3.3984e-02, -2.1228e-02],\n",
      "          [ 1.2529e-02,  8.4231e-03,  1.4063e-02,  4.3138e-02],\n",
      "          [ 3.8179e-02, -4.2356e-02,  4.2503e-02, -2.7871e-02],\n",
      "          [ 2.6228e-02,  6.3867e-03, -4.2021e-02,  3.6769e-02]],\n",
      "\n",
      "         [[ 1.1563e-02, -3.4133e-02,  1.5097e-02, -1.5173e-02],\n",
      "          [-2.1336e-02, -3.3526e-03, -1.5354e-02,  2.9162e-02],\n",
      "          [-4.1817e-02,  9.2302e-03,  3.9625e-03, -3.7410e-02],\n",
      "          [ 3.8945e-02, -3.4636e-02, -1.6537e-02, -1.4945e-02]],\n",
      "\n",
      "         [[ 2.8236e-03,  2.6570e-02,  3.0373e-02, -2.9332e-02],\n",
      "          [ 3.4499e-02,  2.9912e-03, -1.7737e-02,  2.4202e-02],\n",
      "          [ 6.5918e-03, -2.9191e-02, -2.1985e-02, -4.2443e-02],\n",
      "          [ 1.7651e-02, -1.3052e-02,  5.3181e-03,  3.4203e-02]],\n",
      "\n",
      "         [[ 3.6222e-03,  2.9995e-02,  7.1147e-03, -5.9664e-03],\n",
      "          [ 2.6625e-02, -9.4075e-04,  2.6060e-02,  2.9536e-02],\n",
      "          [-1.8056e-02,  1.3912e-02,  4.3987e-02,  2.2446e-02],\n",
      "          [ 4.1269e-02, -3.5204e-02,  3.9256e-02, -1.5311e-02]],\n",
      "\n",
      "         [[ 3.0004e-02, -2.7124e-02,  3.5130e-02,  4.1620e-06],\n",
      "          [-2.5292e-02, -2.0096e-02,  3.2093e-02, -2.3465e-03],\n",
      "          [-3.4929e-02,  2.6199e-02,  2.1100e-02, -7.2256e-03],\n",
      "          [ 1.4949e-02, -6.8601e-03, -1.7923e-02, -1.6121e-03]],\n",
      "\n",
      "         [[-3.3733e-02, -9.7985e-03, -1.2093e-02, -2.3811e-02],\n",
      "          [ 2.3377e-02, -6.6097e-03,  1.3715e-02, -1.1667e-02],\n",
      "          [ 3.4800e-02,  4.1386e-02,  4.3647e-02,  3.0253e-02],\n",
      "          [-2.9321e-02, -4.1028e-03, -5.7591e-03,  2.7056e-02]],\n",
      "\n",
      "         [[ 1.3993e-02, -1.4268e-02, -3.9588e-02, -3.9372e-02],\n",
      "          [-4.1946e-02,  7.1471e-03, -2.2936e-02,  1.2449e-02],\n",
      "          [-2.8198e-02,  3.2717e-02, -3.2538e-02, -2.7149e-02],\n",
      "          [-2.8718e-02, -1.7211e-02, -1.8933e-02,  3.4432e-02]],\n",
      "\n",
      "         [[-3.2018e-02,  2.8714e-02, -1.2848e-02, -2.2530e-02],\n",
      "          [-1.3779e-02, -4.0981e-02,  3.2209e-02,  1.7369e-02],\n",
      "          [ 2.8507e-02, -3.0063e-02,  2.0563e-03,  2.3365e-02],\n",
      "          [ 1.2894e-02,  3.8146e-02,  3.4147e-02, -3.5046e-02]],\n",
      "\n",
      "         [[-3.9128e-02, -2.0078e-02,  1.4909e-02, -4.4554e-03],\n",
      "          [-1.1408e-02,  3.2040e-02, -2.6789e-02,  5.4120e-03],\n",
      "          [ 3.5102e-02, -4.3815e-02,  3.7223e-02, -9.3959e-03],\n",
      "          [ 2.2479e-02,  4.3961e-02, -4.0618e-02, -4.3168e-02]],\n",
      "\n",
      "         [[-6.6139e-03, -2.0467e-02,  2.6239e-02,  2.2104e-02],\n",
      "          [-1.6342e-02,  5.7373e-03, -3.2176e-02, -4.0888e-02],\n",
      "          [ 1.6033e-02, -1.3566e-02, -1.4096e-02,  2.5976e-02],\n",
      "          [ 7.1006e-03, -2.2064e-02, -3.1666e-02,  2.2944e-02]],\n",
      "\n",
      "         [[-3.3352e-02, -3.8767e-02, -1.6597e-02, -1.7102e-02],\n",
      "          [-1.0919e-02, -7.0369e-03,  1.1605e-02,  2.2586e-02],\n",
      "          [-2.9937e-02,  2.1378e-03,  1.8130e-02,  7.0443e-03],\n",
      "          [-1.7285e-02,  6.1914e-03,  4.2347e-02,  4.4097e-02]],\n",
      "\n",
      "         [[ 4.3758e-02,  3.4768e-02, -3.5993e-02,  2.5368e-02],\n",
      "          [-4.1816e-02, -8.0071e-03, -1.6559e-02,  1.9984e-02],\n",
      "          [ 2.5441e-02,  1.6451e-02, -8.6670e-03, -3.1092e-04],\n",
      "          [ 2.1906e-02, -2.0741e-02,  1.1129e-02, -2.0268e-02]],\n",
      "\n",
      "         [[-1.2226e-02, -4.4148e-02,  7.5069e-03,  4.0071e-02],\n",
      "          [-1.2370e-03, -2.1697e-02, -1.6563e-02, -3.6211e-02],\n",
      "          [ 3.2111e-02,  6.6426e-03,  3.2330e-02, -1.1632e-02],\n",
      "          [-3.8499e-02,  2.8268e-02,  4.0190e-03,  2.6677e-02]],\n",
      "\n",
      "         [[ 2.1034e-02,  7.7412e-03,  2.3544e-02, -4.0813e-02],\n",
      "          [-1.5384e-02, -4.3247e-03, -2.9185e-03,  8.8352e-03],\n",
      "          [ 4.0099e-02, -1.3098e-02, -2.3538e-02,  5.3339e-04],\n",
      "          [-1.2420e-02,  3.4454e-02, -3.6228e-02,  9.1695e-03]],\n",
      "\n",
      "         [[ 3.3267e-02,  3.0650e-02,  4.3715e-02, -3.2146e-03],\n",
      "          [ 2.4986e-02,  4.2086e-03,  5.5280e-03, -3.8544e-02],\n",
      "          [-2.4231e-03,  2.4699e-02,  8.8239e-04, -2.9734e-02],\n",
      "          [ 8.1265e-03,  3.1373e-02,  4.1912e-03, -2.3875e-02]],\n",
      "\n",
      "         [[ 7.4193e-03, -2.0380e-02, -2.5723e-02,  3.3889e-03],\n",
      "          [-3.1039e-02,  1.1905e-02, -2.0242e-02,  8.1871e-03],\n",
      "          [-7.4175e-03,  4.3667e-02, -1.4850e-02,  2.5519e-03],\n",
      "          [ 3.0223e-02,  3.4257e-02,  1.5529e-02,  1.3903e-02]],\n",
      "\n",
      "         [[ 2.0019e-02,  2.0705e-03,  3.6222e-02,  2.2996e-02],\n",
      "          [-2.2691e-02, -2.3460e-02, -4.4062e-02,  8.0893e-03],\n",
      "          [ 5.0323e-05, -7.4279e-03,  2.5466e-02, -3.3053e-02],\n",
      "          [ 4.0364e-02, -2.3683e-02,  4.5849e-03,  3.1711e-03]],\n",
      "\n",
      "         [[-3.1459e-02,  3.8556e-02,  3.9338e-02, -2.5504e-02],\n",
      "          [ 3.2893e-02, -3.8259e-02, -5.9866e-03, -1.8820e-02],\n",
      "          [-3.9380e-02, -4.1279e-02, -3.0376e-02,  1.0916e-02],\n",
      "          [ 3.3025e-02, -2.8571e-02,  6.2938e-03, -2.6911e-02]],\n",
      "\n",
      "         [[-2.9090e-02,  2.5439e-02, -2.9631e-02, -1.1994e-02],\n",
      "          [ 2.1240e-02,  3.3932e-02, -1.6554e-02,  2.2057e-02],\n",
      "          [-3.5578e-02,  2.5790e-03,  2.4778e-02, -7.4926e-03],\n",
      "          [ 1.6989e-02,  3.6531e-02, -2.3072e-02,  1.8875e-02]],\n",
      "\n",
      "         [[ 2.6628e-02, -1.0468e-03,  3.0641e-02,  1.6091e-02],\n",
      "          [-6.4263e-03, -2.6993e-02, -2.0338e-02, -9.9036e-03],\n",
      "          [ 1.2783e-02,  1.8500e-02, -1.9023e-02,  3.3937e-02],\n",
      "          [ 3.6647e-02, -2.6127e-02, -3.6475e-02, -4.3460e-02]],\n",
      "\n",
      "         [[-2.3599e-02, -7.4247e-03,  1.8908e-02, -9.6800e-03],\n",
      "          [-3.4982e-02,  9.2745e-03, -6.0713e-03,  1.6871e-02],\n",
      "          [ 3.0983e-02,  9.9705e-03, -3.5796e-02, -2.3672e-02],\n",
      "          [-2.0586e-02, -2.1283e-02,  2.8940e-02,  1.3662e-02]],\n",
      "\n",
      "         [[ 2.2863e-02, -7.5732e-03, -1.1338e-02,  3.9221e-02],\n",
      "          [ 1.8265e-03, -1.1637e-02, -3.3758e-02,  4.0624e-02],\n",
      "          [ 3.4056e-03,  4.3321e-02, -3.3768e-03, -1.0927e-03],\n",
      "          [-2.4002e-03,  3.6780e-02,  3.1873e-02,  4.0721e-02]],\n",
      "\n",
      "         [[ 3.6254e-02,  1.2895e-02,  1.4772e-02, -2.7875e-02],\n",
      "          [-2.3387e-02, -4.2544e-02,  3.4611e-02,  1.6071e-02],\n",
      "          [-1.3411e-03, -1.0438e-02, -8.7957e-04, -3.1289e-02],\n",
      "          [ 1.7326e-02, -1.0241e-02, -8.3353e-03, -4.5256e-03]],\n",
      "\n",
      "         [[ 1.4166e-02, -1.9235e-02,  1.5423e-03,  2.0101e-03],\n",
      "          [-2.1968e-02,  3.8743e-02, -1.6916e-02, -3.0279e-02],\n",
      "          [ 2.5653e-02, -1.5200e-02, -1.4760e-02,  7.1035e-03],\n",
      "          [-3.3817e-02,  9.2242e-03, -8.0402e-03, -3.3068e-02]]]])\n",
      "------------------------\n",
      "Layer: disc.2.0.bias, Shape: torch.Size([1])\n",
      "Weights: tensor([0.0167])\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for name,param in disc.named_parameters():\n",
    "    print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "    print(f\"Weights: {param.data}\")\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1051, -0.9090, -0.2299, -1.1468,  0.2687,  1.1767,  1.4063,  1.0764,\n",
      "          0.0237, -0.5532]])\n",
      "tensor([[[[-1.1051]],\n",
      "\n",
      "         [[-0.9090]],\n",
      "\n",
      "         [[-0.2299]],\n",
      "\n",
      "         [[-1.1468]],\n",
      "\n",
      "         [[ 0.2687]],\n",
      "\n",
      "         [[ 1.1767]],\n",
      "\n",
      "         [[ 1.4063]],\n",
      "\n",
      "         [[ 1.0764]],\n",
      "\n",
      "         [[ 0.0237]],\n",
      "\n",
      "         [[-0.5532]]]])\n"
     ]
    }
   ],
   "source": [
    "x = get_noise(1,10)\n",
    "print(x)\n",
    "print(gen.unsqueeze_noise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc_output: tensor([[-0.3987]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gen_img = gen.forward(x)\n",
    "show_tensor_img(gen_img)\n",
    "print(\"disc_output:\",disc.forward(gen_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.',download=True,transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(),lr = lr, betas=(beta_1,beta_2))\n",
    "disc = Discriminator().to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(),lr=lr, betas=(beta_1,beta_2))\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight,0.0,0.02)\n",
    "    if isinstance(m,nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight,0.0,0.02)\n",
    "        torch.nn.init.constant_(m.bias,0)\n",
    "\n",
    "gen = gen.apply(weight_init)\n",
    "disc = disc.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (gen): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(64, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 469 Generator loss: 4.383543118958562 Discriminator loss: 4.383543118958562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 938 Generator loss: 0.09898625717473535 Discriminator loss: 0.09898625717473535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 1407 Generator loss: 0.08206310236467561 Discriminator loss: 0.08206310236467561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 1876 Generator loss: 0.06921738009259669 Discriminator loss: 0.06921738009259669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 2345 Generator loss: 0.09950154853362489 Discriminator loss: 0.09950154853362489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 2814 Generator loss: 0.08732096699552087 Discriminator loss: 0.08732096699552087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, step 3283 Generator loss: 0.08221528835389333 Discriminator loss: 0.08221528835389333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, step 3752 Generator loss: 0.07752952700023565 Discriminator loss: 0.07752952700023565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 4221 Generator loss: 0.07013390142492605 Discriminator loss: 0.07013390142492605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 4690 Generator loss: 0.06438214159963096 Discriminator loss: 0.06438214159963096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 5159 Generator loss: 0.0584640362741128 Discriminator loss: 0.0584640362741128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, step 5628 Generator loss: 0.054353743731422814 Discriminator loss: 0.054353743731422814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, step 6097 Generator loss: 0.05054667331483995 Discriminator loss: 0.05054667331483995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 6566 Generator loss: 0.04784648552916521 Discriminator loss: 0.04784648552916521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, step 7035 Generator loss: 0.04517179241125421 Discriminator loss: 0.04517179241125421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, step 7504 Generator loss: 0.04290370041564896 Discriminator loss: 0.04290370041564896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, step 7973 Generator loss: 0.04064029024950757 Discriminator loss: 0.04064029024950757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, step 8442 Generator loss: 0.03833563067362579 Discriminator loss: 0.03833563067362579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, step 8911 Generator loss: 0.03660272320421051 Discriminator loss: 0.03660272320421051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, step 9380 Generator loss: 0.03495813647293418 Discriminator loss: 0.03495813647293418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, step 9849 Generator loss: 0.033369296087464966 Discriminator loss: 0.033369296087464966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, step 10318 Generator loss: 0.03191093241758302 Discriminator loss: 0.03191093241758302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, step 10787 Generator loss: 0.030607760082425522 Discriminator loss: 0.030607760082425522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, step 11256 Generator loss: 0.02945059323611537 Discriminator loss: 0.02945059323611537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, step 11725 Generator loss: 0.028197974455867615 Discriminator loss: 0.028197974455867615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, step 12194 Generator loss: 0.02712156379277424 Discriminator loss: 0.02712156379277424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, step 12663 Generator loss: 0.026158861256896402 Discriminator loss: 0.026158861256896402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, step 13132 Generator loss: 0.0253012620231022 Discriminator loss: 0.0253012620231022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, step 13601 Generator loss: 0.024451312320003436 Discriminator loss: 0.024451312320003436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, step 14070 Generator loss: 0.023655811993664372 Discriminator loss: 0.023655811993664372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, step 14539 Generator loss: 0.022842644251320328 Discriminator loss: 0.022842644251320328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, step 15008 Generator loss: 0.022156207420078792 Discriminator loss: 0.022156207420078792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, step 15477 Generator loss: 0.021473313265146496 Discriminator loss: 0.021473313265146496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, step 15946 Generator loss: 0.020874942935726507 Discriminator loss: 0.020874942935726507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, step 16415 Generator loss: 0.02023639320009352 Discriminator loss: 0.02023639320009352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, step 16884 Generator loss: 0.019683366395321696 Discriminator loss: 0.019683366395321696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, step 17353 Generator loss: 0.019136063031424427 Discriminator loss: 0.019136063031424427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, step 17822 Generator loss: 0.018611210740043425 Discriminator loss: 0.018611210740043425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, step 18291 Generator loss: 0.018112022180282482 Discriminator loss: 0.018112022180282482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, step 18760 Generator loss: 0.01767550742535497 Discriminator loss: 0.01767550742535497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, step 19229 Generator loss: 0.01722014637750284 Discriminator loss: 0.01722014637750284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, step 19698 Generator loss: 0.016798152948155717 Discriminator loss: 0.016798152948155717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, step 20167 Generator loss: 0.01640733905089155 Discriminator loss: 0.01640733905089155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, step 20636 Generator loss: 0.016022398606793463 Discriminator loss: 0.016022398606793463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, step 21105 Generator loss: 0.015660525261964108 Discriminator loss: 0.015660525261964108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, step 21574 Generator loss: 0.015331873024010305 Discriminator loss: 0.015331873024010305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, step 22043 Generator loss: 0.015001658418236107 Discriminator loss: 0.015001658418236107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, step 22512 Generator loss: 0.014672047516304907 Discriminator loss: 0.014672047516304907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, step 22981 Generator loss: 0.014375815461875299 Discriminator loss: 0.014375815461875299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, step 23450 Generator loss: 0.014077584795794412 Discriminator loss: 0.014077584795794412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, step 23919 Generator loss: 0.013832887935430358 Discriminator loss: 0.013832887935430358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, step 24388 Generator loss: 0.01352716260529797 Discriminator loss: 0.01352716260529797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, step 24857 Generator loss: 0.013263522277379945 Discriminator loss: 0.013263522277379945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:22<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, step 25326 Generator loss: 0.013019433866097269 Discriminator loss: 0.013019433866097269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, step 25795 Generator loss: 0.012780639303307036 Discriminator loss: 0.012780639303307036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, step 26264 Generator loss: 0.012544574109660927 Discriminator loss: 0.012544574109660927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, step 26733 Generator loss: 0.0123210532316798 Discriminator loss: 0.0123210532316798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, step 27202 Generator loss: 0.012108855667661714 Discriminator loss: 0.012108855667661714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, step 27671 Generator loss: 0.011895408037848287 Discriminator loss: 0.011895408037848287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, step 28140 Generator loss: 0.01169550654374899 Discriminator loss: 0.01169550654374899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, step 28609 Generator loss: 0.01149552389732567 Discriminator loss: 0.01149552389732567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, step 29078 Generator loss: 0.011309278738165554 Discriminator loss: 0.011309278738165554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 23.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, step 29547 Generator loss: 0.011129600325702553 Discriminator loss: 0.011129600325702553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, step 30016 Generator loss: 0.010948483311631998 Discriminator loss: 0.010948483311631998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, step 30485 Generator loss: 0.010780097847178396 Discriminator loss: 0.010780097847178396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, step 30954 Generator loss: 0.010614926181680426 Discriminator loss: 0.010614926181680426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 23.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, step 31423 Generator loss: 0.01045373987593814 Discriminator loss: 0.01045373987593814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, step 31892 Generator loss: 0.010296957226626118 Discriminator loss: 0.010296957226626118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, step 32361 Generator loss: 0.010143461093724493 Discriminator loss: 0.010143461093724493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, step 32830 Generator loss: 0.009998491133786609 Discriminator loss: 0.009998491133786609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 23.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, step 33299 Generator loss: 0.009858616350385787 Discriminator loss: 0.009858616350385787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 22.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, step 33768 Generator loss: 0.009716097707507844 Discriminator loss: 0.009716097707507844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, step 34237 Generator loss: 0.00958188586480286 Discriminator loss: 0.00958188586480286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, step 34706 Generator loss: 0.00945082308684214 Discriminator loss: 0.00945082308684214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, step 35175 Generator loss: 0.00931975046185093 Discriminator loss: 0.00931975046185093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, step 35644 Generator loss: 0.009199401178146036 Discriminator loss: 0.009199401178146036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, step 36113 Generator loss: 0.009078404230739716 Discriminator loss: 0.009078404230739716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, step 36582 Generator loss: 0.008962081781450339 Discriminator loss: 0.008962081781450339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, step 37051 Generator loss: 0.00884449371612227 Discriminator loss: 0.00884449371612227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, step 37520 Generator loss: 0.00873449630713418 Discriminator loss: 0.00873449630713418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, step 37989 Generator loss: 0.008626684915225136 Discriminator loss: 0.008626684915225136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:24<00:00, 19.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, step 38458 Generator loss: 0.008520609358136876 Discriminator loss: 0.008520609358136876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, step 38927 Generator loss: 0.008414768652545354 Discriminator loss: 0.008414768652545354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 23.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, step 39396 Generator loss: 0.00831470930805182 Discriminator loss: 0.00831470930805182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, step 39865 Generator loss: 0.008215348006317562 Discriminator loss: 0.008215348006317562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, step 40334 Generator loss: 0.008115880818192587 Discriminator loss: 0.008115880818192587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 19.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, step 40803 Generator loss: 0.008021794924451844 Discriminator loss: 0.008021794924451844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:21<00:00, 22.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, step 41272 Generator loss: 0.007931115219446947 Discriminator loss: 0.007931115219446947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 23.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, step 41741 Generator loss: 0.007838082916227724 Discriminator loss: 0.007838082916227724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 23.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, step 42210 Generator loss: 0.007751863782291242 Discriminator loss: 0.007751863782291242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, step 42679 Generator loss: 0.007666475800322979 Discriminator loss: 0.007666475800322979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, step 43148 Generator loss: 0.007582643258249495 Discriminator loss: 0.007582643258249495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, step 43617 Generator loss: 0.007499640648915342 Discriminator loss: 0.007499640648915342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:23<00:00, 20.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, step 44086 Generator loss: 0.007418847925289727 Discriminator loss: 0.007418847925289727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 23.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, step 44555 Generator loss: 0.007339554386691869 Discriminator loss: 0.007339554386691869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:20<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, step 45024 Generator loss: 0.0072629845883895455 Discriminator loss: 0.0072629845883895455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 23.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, step 45493 Generator loss: 0.007186432485500483 Discriminator loss: 0.007186432485500483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, step 45962 Generator loss: 0.007112908104922887 Discriminator loss: 0.007112908104922887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:19<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, step 46431 Generator loss: 0.007041036564313017 Discriminator loss: 0.007041036564313017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:18<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, step 46900 Generator loss: 0.006971463841887428 Discriminator loss: 0.006971463841887428\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "total_step = 0\n",
    "for epoch in range(n_epochs):\n",
    "    mean_discriminator_loss = 0\n",
    "    mean_generator_loss = 0\n",
    "    total_step = 0\n",
    "    for real,_ in tqdm(dataloader):\n",
    "        total_step += 1\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise = get_noise(cur_batch_size,z_dim,device=device)\n",
    "        fake = gen(fake_noise)\n",
    "\n",
    "        disc_fake_pred = disc(fake.detach())\n",
    "        disc_fake_loss = criterion(disc_fake_pred,torch.zeros_like(disc_fake_pred))\n",
    "\n",
    "        disc_real_pred = disc(real)\n",
    "        disc_real_loss = criterion(disc_real_pred,torch.ones_like(disc_real_pred))\n",
    "\n",
    "        disc_loss = (disc_fake_loss+disc_real_loss)/2\n",
    "\n",
    "        mean_discriminator_loss += disc_loss.item() / total_step\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step()\n",
    "\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size,z_dim,device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss=criterion(disc_fake_pred,torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        mean_generator_loss += gen_loss.item() /total_step\n",
    "        # if cur_step % display_step == 0 and cur_step > 0 :\n",
    "\n",
    "        cur_step += 1\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'cur_step': cur_step,\n",
    "        'gen_state_dict': gen.state_dict(),\n",
    "        'gen_opt_state_dict': gen_opt.state_dict(),\n",
    "        'disc_state_dict': disc.state_dict(),\n",
    "        'disc_opt_state_dict': disc_opt.state_dict(),\n",
    "        'mean_generator_loss': mean_generator_loss,\n",
    "        'mean_discriminator_loss': mean_discriminator_loss\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, f'/mnt/d/ML_playground/Learn_GAN/when-I-learn-GAN/DCGAN/checkpoint/100checkpoint.pt')\n",
    "    print(f'Epoch {epoch}, step {cur_step} Generator loss: {mean_generator_loss} Discriminator loss: {mean_discriminator_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_noise = get_noise(1,64,device='cuda')\n",
    "test_gen = gen.forward(test_noise)\n",
    "show_tensor_img(test_gen.detach(),num_imgs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = torch.load('/mnt/d/ML_playground/Learn_GAN/when-I-learn-GAN/DCGAN/checkpoint/checkpoint.pt')  # Load the checkpoint\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "device = 'cuda'\n",
    "\n",
    "# Load the generator and discriminator models\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen.load_state_dict(checkpoint['gen_state_dict'])\n",
    "disc = Discriminator().to(device)\n",
    "disc.load_state_dict(checkpoint['disc_state_dict'])\n",
    "\n",
    "# Load the optimizer states if necessary\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "gen_opt.load_state_dict(checkpoint['gen_opt_state_dict'])\n",
    "disc_opt.load_state_dict(checkpoint['disc_opt_state_dict'])\n",
    "\n",
    "# Load other necessary variables\n",
    "epoch = checkpoint['epoch']\n",
    "cur_step = checkpoint['cur_step']\n",
    "mean_generator_loss = checkpoint['mean_generator_loss']\n",
    "mean_discriminator_loss = checkpoint['mean_discriminator_loss']\n",
    "\n",
    "test_noise = get_noise(1,64,device='cuda')\n",
    "test_gen = gen.forward(test_noise)\n",
    "show_tensor_img(test_gen.detach(),num_imgs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
